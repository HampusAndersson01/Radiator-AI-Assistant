version: "3.8"
services:
  ai_service:
    build:
      context: ./ai_service
      dockerfile: Dockerfile
    image: radiator-ai-service:latest
    ports:
      - "8000:8000"
    environment:
      - TELEGRAM_WEBHOOK=${TELEGRAM_WEBHOOK}
    volumes:
      - ai_models:/app/models
      - ai_state:/app
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  bot:
    build:
      context: ./bot
      dockerfile: Dockerfile
    image: radiator-bot:latest
    environment:
      - BOT_TOKEN=${BOT_TOKEN}
      - AI_URL=http://ai_service:8000/train
    depends_on:
      - ai_service
    restart: unless-stopped

volumes:
  ai_models:
  ai_state:
